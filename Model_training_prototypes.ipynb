{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_training_prototypes.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO9Hqbsd4h7QMf05Nd4TfK3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cleysonl/ML_Bootcamp_CLL/blob/master/Model_training_prototypes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mQWMaoCauKm",
        "colab_type": "text"
      },
      "source": [
        "### **Load Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpGQcBklaxXe",
        "colab_type": "code",
        "outputId": "edfc423f-6164-40e6-ecf4-5339c77cd922",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0.alpha0"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.0.0.alpha0 in /usr/local/lib/python3.6/dist-packages (2.0.0a0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.1.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.1.0)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.14.0a20190301)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.27.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.34.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.17.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.9.0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.14.0.dev2019030115)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0.alpha0) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (3.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0.alpha0) (45.1.0)\n",
            "Requirement already satisfied: tensorflow-gpu==2.0.0.alpha0 in /usr/local/lib/python3.6/dist-packages (2.0.0a0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.27.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.1.0)\n",
            "Requirement already satisfied: tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.14.0.dev2019030115)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.17.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.1.8)\n",
            "Requirement already satisfied: tb-nightly<1.14.0a20190302,>=1.14.0a20190301 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.14.0a20190301)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (0.34.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0.alpha0) (1.0.8)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0.alpha0) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0.alpha0) (45.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0.alpha0) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N39sGe01OyiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category = FutureWarning)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import subprocess\n",
        "import cv2\n",
        "import json\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bS9Ff4_MbkDY",
        "colab_type": "text"
      },
      "source": [
        "## **Building & Deploying an Apparel Classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnBvNNQuc-Fc",
        "colab_type": "text"
      },
      "source": [
        "### **Load Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFDwyEmcbdvl",
        "colab_type": "code",
        "outputId": "ccfe546b-c265-49ff-8d64-fcf20968087a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "print('\\nTrain_images.shape: {}, of {}'.format(train_images.shape, train_images.dtype))\n",
        "print('Test_images.shape: {}, of {}'.format(test_images.shape, test_images.dtype))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train_images.shape: (60000, 28, 28), of uint8\n",
            "Test_images.shape: (10000, 28, 28), of uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1HPiVwgQWLY",
        "colab_type": "text"
      },
      "source": [
        "## **Training a simple CNN model from Scratch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UcIJdu4Qbr8",
        "colab_type": "text"
      },
      "source": [
        "### **Reshaping Image Data for Modeling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9V9PtvnLbp64",
        "colab_type": "code",
        "outputId": "901905c1-4c80-40cd-d675-bbe99aea238c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#reshape for feeding into the model\n",
        "train_images_gr = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
        "test_images_gr = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
        "\n",
        "print('\\nTrain_images.shape: {}, of {}'.format(train_images_gr.shape, train_images_gr.dtype))\n",
        "print('\\nTest_images.shape: {}, of {}'.format(test_images_gr.shape, test_images_gr.dtype))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train_images.shape: (60000, 28, 28, 1), of uint8\n",
            "\n",
            "Test_images.shape: (10000, 28, 28, 1), of uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOUxSlGdQ5vO",
        "colab_type": "text"
      },
      "source": [
        "### **Visualize sample images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7uJctpORY7L",
        "colab_type": "code",
        "outputId": "f6a1d10c-8504-475d-aeed-89ad945994ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "source": [
        "fig, ax = plt.subplots(2, 5, figsize=(12, 6))\n",
        "ax[0, 0].imshow(train_images_gr[0].reshape(28, 28))\n",
        "ax[0, 1].imshow(train_images_gr[1].reshape(28, 28))\n",
        "ax[0, 2].imshow(train_images_gr[2].reshape(28, 28))\n",
        "ax[0, 3].imshow(train_images_gr[3].reshape(28, 28))\n",
        "ax[0, 4].imshow(train_images_gr[4].reshape(28, 28))\n",
        "ax[1, 0].imshow(train_images_gr[5].reshape(28, 28))\n",
        "ax[1, 1].imshow(train_images_gr[6].reshape(28, 28))\n",
        "ax[1, 2].imshow(train_images_gr[7].reshape(28, 28))\n",
        "ax[1, 3].imshow(train_images_gr[8].reshape(28, 28))\n",
        "ax[1, 4].imshow(train_images_gr[9].reshape(28, 28))\n",
        "\n",
        "print([class_names[i] for i in train_labels[:10]])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ankle boot', 'T-shirt/top', 'T-shirt/top', 'Dress', 'T-shirt/top', 'Pullover', 'Sneaker', 'Pullover', 'Sandal', 'Sandal']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr8AAAFGCAYAAABjbPeiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x432 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf8AmJlTSwYB",
        "colab_type": "text"
      },
      "source": [
        "### **Build CNN Model Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7jDbsJOSahX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_SHAPE = (28, 28, 1)\n",
        "\n",
        "def create_cnn_architecture_model1(input_shape):\n",
        "  inp = keras.layers.Input(shape = input_shape)\n",
        "\n",
        "  conv1 = keras.layers.Conv2D(filters=16, kernel_size = (3,3), strides = (1,1), activation = 'relu', padding='same')(inp)\n",
        "  pool1 = keras.layers.MaxPooling2D(pool_size = (2,2))(conv1)\n",
        "  conv2 = keras.layers.Conv2D(filters=32, kernel_size = (3,3), strides = (1,1), activation = 'relu', padding='same')(pool1)\n",
        "  pool2 = keras.layers.MaxPooling2D(pool_size =(2, 2))(conv2)\n",
        "\n",
        "  flat = keras.layers.Flatten()(pool2)\n",
        "\n",
        "  hidden1 = keras.layers.Dense(256, activation='relu')(flat)\n",
        "  drop1 = keras.layers.Dropout(rate=0.3)(hidden1)\n",
        "\n",
        "  out = keras.layers.Dense(10, activation = 'softmax')(drop1)\n",
        "\n",
        "  model = keras.Model(inputs=inp, outputs=out)\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9zYOYEPYcVB",
        "colab_type": "code",
        "outputId": "057662f8-540a-4782-d46a-92eb04ad5d63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "model = create_cnn_architecture_model1(input_shape=INPUT_SHAPE)\n",
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 14, 14, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 1568)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 256)               401664    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 409,034\n",
            "Trainable params: 409,034\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1p9QcUMiasgv",
        "colab_type": "text"
      },
      "source": [
        "### **Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYMgCstdY0cP",
        "colab_type": "code",
        "outputId": "b6aef9d5-637e-4bc6-ed53-aea3f2751218",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "EPOCHS = 10\n",
        "train_images_scaled = train_images_gr / 255.\n",
        "model.fit(train_images_scaled, train_labels, validation_split=0.1, epochs=EPOCHS)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/10\n",
            "54000/54000 [==============================] - 8s 140us/sample - loss: 0.4582 - accuracy: 0.8333 - val_loss: 0.3339 - val_accuracy: 0.8773\n",
            "Epoch 2/10\n",
            "54000/54000 [==============================] - 7s 138us/sample - loss: 0.3082 - accuracy: 0.8880 - val_loss: 0.2759 - val_accuracy: 0.8975\n",
            "Epoch 3/10\n",
            "54000/54000 [==============================] - 7s 134us/sample - loss: 0.2643 - accuracy: 0.9027 - val_loss: 0.2587 - val_accuracy: 0.9027\n",
            "Epoch 4/10\n",
            "54000/54000 [==============================] - 8s 139us/sample - loss: 0.2346 - accuracy: 0.9129 - val_loss: 0.2483 - val_accuracy: 0.9087\n",
            "Epoch 5/10\n",
            "54000/54000 [==============================] - 7s 135us/sample - loss: 0.2116 - accuracy: 0.9216 - val_loss: 0.2394 - val_accuracy: 0.9137\n",
            "Epoch 6/10\n",
            "54000/54000 [==============================] - 8s 142us/sample - loss: 0.1892 - accuracy: 0.9287 - val_loss: 0.2404 - val_accuracy: 0.9132\n",
            "Epoch 7/10\n",
            "54000/54000 [==============================] - 7s 137us/sample - loss: 0.1738 - accuracy: 0.9341 - val_loss: 0.2322 - val_accuracy: 0.9178\n",
            "Epoch 8/10\n",
            "54000/54000 [==============================] - 7s 135us/sample - loss: 0.1570 - accuracy: 0.9413 - val_loss: 0.2308 - val_accuracy: 0.9158\n",
            "Epoch 9/10\n",
            "54000/54000 [==============================] - 7s 134us/sample - loss: 0.1414 - accuracy: 0.9475 - val_loss: 0.2318 - val_accuracy: 0.9213\n",
            "Epoch 10/10\n",
            "54000/54000 [==============================] - 7s 134us/sample - loss: 0.1280 - accuracy: 0.9514 - val_loss: 0.2569 - val_accuracy: 0.9187\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6e0029be10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwWyBtktcq51",
        "colab_type": "text"
      },
      "source": [
        "### **Save Model Weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIlY3JUZcDsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.isdir('model_weights/'):\n",
        "  os.mkdir('model_weights/')\n",
        "\n",
        "model.save_weights(filepath= 'model_weights/cnn_model1_wt.h5', overwrite=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eu2kGWLsdfff",
        "colab_type": "text"
      },
      "source": [
        "### **Build Model Architecture and Load Model Weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAfj1-s6dEYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_cnn_architecture_model1(input_shape=INPUT_SHAPE)\n",
        "model.load_weights('model_weights/cnn_model1_wt.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dQBdP6neKvQ",
        "colab_type": "text"
      },
      "source": [
        "### **Evaluate Model Performance on Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RReUlOLsdzK1",
        "colab_type": "code",
        "outputId": "251040f0-ff60-4e60-f6c8-92ee1c72b884",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "test_images_scaled = test_images_gr / 255.\n",
        "predictions = model.predict(test_images_scaled)\n",
        "predictions[:5]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.91746677e-09, 1.35540759e-10, 4.29188421e-11, 1.10093167e-11,\n",
              "        2.38737207e-11, 2.30706561e-07, 2.09750731e-10, 3.25475085e-05,\n",
              "        2.46321324e-10, 9.99967217e-01],\n",
              "       [8.45491450e-05, 1.06394644e-15, 9.99633908e-01, 4.37942083e-09,\n",
              "        2.69504264e-04, 1.23420441e-11, 1.19919841e-05, 1.20488233e-12,\n",
              "        4.17839235e-10, 1.70722838e-13],\n",
              "       [1.59540773e-14, 1.00000000e+00, 3.32995187e-21, 3.48099175e-17,\n",
              "        1.67730175e-20, 4.90836312e-26, 1.89485787e-17, 5.05495522e-30,\n",
              "        2.01704745e-20, 6.29935622e-28],\n",
              "       [4.26310158e-15, 1.00000000e+00, 1.34694811e-20, 1.18525626e-17,\n",
              "        4.30946339e-19, 4.07023199e-26, 7.57136871e-19, 7.02375789e-31,\n",
              "        1.68948664e-24, 1.24775986e-26],\n",
              "       [1.51950233e-02, 1.40396126e-12, 2.94838357e-03, 8.26478299e-07,\n",
              "        8.77792074e-04, 7.56561747e-09, 9.80978012e-01, 1.23232700e-11,\n",
              "        2.59819721e-09, 1.39045024e-08]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEXgEpUqeahW",
        "colab_type": "code",
        "outputId": "6719798d-297a-4000-a60e-34985fd077c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "prediction_labels = np.argmax(predictions, axis=1)\n",
        "prediction_labels[:5]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 1, 1, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9A2jTuRek6z",
        "colab_type": "code",
        "outputId": "fa9bf3db-f7b1-474e-a73e-87fc51ce5eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "print(classification_report(test_labels, prediction_labels, target_names = class_names))\n",
        "pd.DataFrame(confusion_matrix(test_labels, prediction_labels), index=class_names, columns = class_names)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            " T-shirt/top       0.86      0.86      0.86      1000\n",
            "     Trouser       0.99      0.98      0.99      1000\n",
            "    Pullover       0.88      0.86      0.87      1000\n",
            "       Dress       0.90      0.94      0.92      1000\n",
            "        Coat       0.87      0.84      0.86      1000\n",
            "      Sandal       0.98      0.98      0.98      1000\n",
            "       Shirt       0.74      0.76      0.75      1000\n",
            "     Sneaker       0.95      0.97      0.96      1000\n",
            "         Bag       0.98      0.98      0.98      1000\n",
            "  Ankle boot       0.98      0.95      0.97      1000\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.91      0.91     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T-shirt/top</th>\n",
              "      <th>Trouser</th>\n",
              "      <th>Pullover</th>\n",
              "      <th>Dress</th>\n",
              "      <th>Coat</th>\n",
              "      <th>Sandal</th>\n",
              "      <th>Shirt</th>\n",
              "      <th>Sneaker</th>\n",
              "      <th>Bag</th>\n",
              "      <th>Ankle boot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>T-shirt/top</th>\n",
              "      <td>859</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>113</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Trouser</th>\n",
              "      <td>1</td>\n",
              "      <td>984</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pullover</th>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>861</td>\n",
              "      <td>7</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dress</th>\n",
              "      <td>19</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>936</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Coat</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "      <td>48</td>\n",
              "      <td>838</td>\n",
              "      <td>0</td>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sandal</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>985</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Shirt</th>\n",
              "      <td>91</td>\n",
              "      <td>2</td>\n",
              "      <td>57</td>\n",
              "      <td>27</td>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "      <td>762</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sneaker</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>973</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bag</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>985</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ankle boot</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>955</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             T-shirt/top  Trouser  Pullover  ...  Sneaker  Bag  Ankle boot\n",
              "T-shirt/top          859        0        11  ...        0    5           0\n",
              "Trouser                1      984         0  ...        0    1           0\n",
              "Pullover              20        1       861  ...        0    1           0\n",
              "Dress                 19        6         7  ...        0    2           0\n",
              "Coat                   1        0        47  ...        0    0           0\n",
              "Sandal                 1        0         0  ...       11    0           3\n",
              "Shirt                 91        2        57  ...        0    7           0\n",
              "Sneaker                0        0         0  ...      973    0          14\n",
              "Bag                    3        0         0  ...        1  985           0\n",
              "Ankle boot             0        0         0  ...       38    0         955\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwE68vtufYYl",
        "colab_type": "text"
      },
      "source": [
        "## **Fine-tuning a pre-trained ResNet-50 CNN Model***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcljpkSaf4ta",
        "colab_type": "text"
      },
      "source": [
        "### **Build CNN Model Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMHupwMgfTH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_SHAPE_RN = (32, 32, 3)\n",
        "\n",
        "def create_cnn_architecture_model2(input_shape):\n",
        "  inc_net = keras.applications.resnet50.ResNet50(include_top=False, weights = 'imagenet', input_shape = input_shape)\n",
        "  inc_net.trainable = True\n",
        "  # Fine-tune the layers\n",
        "  for layer in inc_net.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "  base_inc = inc_net\n",
        "  base_out = base_inc.output\n",
        "  pool_out = keras.layers.Flatten()(base_out)\n",
        "\n",
        "  hidden1 = keras.layers.Dense(units = 512, activation = 'relu')(pool_out)\n",
        "  drop1 = keras.layers.Dropout(rate = 0.3)(hidden1)\n",
        "  hidden2 = keras.layers.Dense(units = 512, activation = 'relu')(drop1)\n",
        "  drop2 = keras.layers.Dropout(rate = 0.3)(hidden2) \n",
        "\n",
        "  out = keras.layers.Dense(units = 10, activation = 'softmax')(drop2)\n",
        "\n",
        "  model = keras.Model(inputs = base_inc.input, outputs = out)\n",
        "  model.compile(optimizer = keras.optimizers.RMSprop(lr= 1e-4), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmQXuBWcpKL1",
        "colab_type": "code",
        "outputId": "37b35de5-01cd-496a-92c1-e2b428814ac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model2 = create_cnn_architecture_model2(input_shape = INPUT_SHAPE_RN)\n",
        "model2.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalizationV1) (None, 16, 16, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_98 (Activation)      (None, 16, 16, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           activation_98[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 8, 8, 64)     4160        max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 8, 8, 64)     0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 8, 8, 64)     0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 8, 8, 256)    16640       max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 8, 8, 256)    1024        res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 8, 8, 256)    0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 8, 8, 256)    0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 8, 8, 64)     16448       activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 8, 8, 64)     0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 8, 8, 64)     0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, 8, 8, 256)    0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 8, 8, 256)    0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2a (Conv2D)         (None, 8, 8, 64)     16448       activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 8, 8, 64)     0           bn2c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 8, 8, 64)     0           bn2c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2c_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2c_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, 8, 8, 256)    0           bn2c_branch2c[0][0]              \n",
            "                                                                 activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 8, 8, 256)    0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 4, 4, 128)    32896       activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 4, 4, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 4, 4, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 4, 4, 512)    131584      activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 4, 4, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, 4, 4, 512)    0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 4, 4, 512)    0           add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 4, 4, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 4, 4, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, 4, 4, 512)    0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 4, 4, 512)    0           add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 4, 4, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 4, 4, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, 4, 4, 512)    0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 4, 4, 512)    0           add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 4, 4, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 4, 4, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, 4, 4, 512)    0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 4, 4, 512)    0           add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 2, 2, 256)    131328      activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 2, 2, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 2, 2, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 2, 2, 1024)   525312      activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 2, 2, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, 2, 2, 1024)   0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 2, 2, 1024)   0           add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 2, 2, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 2, 2, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, 2, 2, 1024)   0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 2, 2, 1024)   0           add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 2, 2, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 2, 2, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, 2, 2, 1024)   0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 2, 2, 1024)   0           add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 2, 2, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 2, 2, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, 2, 2, 1024)   0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 2, 2, 1024)   0           add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 2, 2, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 2, 2, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, 2, 2, 1024)   0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 2, 2, 1024)   0           add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 2, 2, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 2, 2, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, 2, 2, 1024)   0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 2, 2, 1024)   0           add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 1, 1, 512)    524800      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 1, 1, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 1, 1, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 1, 1, 2048)   2099200     activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 1, 1, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, 1, 1, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 1, 1, 2048)   0           add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 1, 1, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 1, 1, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, 1, 1, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 1, 1, 2048)   0           add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 1, 1, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 1, 1, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, 1, 1, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 1, 1, 2048)   0           add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 2048)         0           activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 512)          1049088     flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 512)          0           dense_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 512)          262656      dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 512)          0           dense_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 10)           5130        dropout_9[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 24,904,586\n",
            "Trainable params: 24,851,466\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrsNQ6Q5tbmq",
        "colab_type": "text"
      },
      "source": [
        "### **Reshaping Image Data for Modeling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vlScXULuVO5",
        "colab_type": "code",
        "outputId": "8a7bab6d-9557-44df-ac4b-7d7d6c45c100",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train_images_3ch = np.stack([train_images]*3, axis=-1)\n",
        "test_images_3ch = np.stack([test_images]*3, axis=-1)\n",
        "\n",
        "print('\\nTrain_images.shape: {}, of {}'.format(train_images_3ch.shape, train_images_3ch.dtype))\n",
        "print('Test_images.shape: {}, of {}'.format(test_images_3ch.shape, test_images_3ch.dtype))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train_images.shape: (60000, 28, 28, 3), of uint8\n",
            "Test_images.shape: (10000, 28, 28, 3), of uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0j2I34PEp605",
        "colab_type": "text"
      },
      "source": [
        "### **Resizing Image data for Modeling**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4NeVnLnpWVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "\n",
        "def resize_image_array(img, img_size_dims):\n",
        "  img = cv2.resize(img, dsize = img_size_dims, interpolation = cv2.INTER_CUBIC)\n",
        "  img = np.array(img, dtype = np.float32)\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7EbQowQqdSl",
        "colab_type": "code",
        "outputId": "42d140d3-0dee-4bab-dd1c-1c6772ab28db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "IMG_DIMS = (32, 32)\n",
        "\n",
        "train_images_3ch = np.array([resize_image_array(img, img_size_dims = IMG_DIMS) for img in train_images_3ch])\n",
        "test_images_3ch = np.array([resize_image_array(img, img_size_dims = IMG_DIMS) for img in test_images_3ch])\n",
        "\n",
        "print('\\nTrain_images.shape: {}, of {}'.format(train_images_3ch.shape, train_images_3ch.dtype))\n",
        "print('\\nTest_images.shape: {}, of {}'.format(test_images_3ch.shape, test_images_3ch.dtype))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train_images.shape: (60000, 32, 32, 3), of float32\n",
            "\n",
            "Test_images.shape: (10000, 32, 32, 3), of float32\n",
            "CPU times: user 1.5 s, sys: 1.02 s, total: 2.51 s\n",
            "Wall time: 2.52 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyh3Syhjulqo",
        "colab_type": "text"
      },
      "source": [
        "### **Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuOS-NfFr9Dj",
        "colab_type": "code",
        "outputId": "647f04d8-0489-4f6b-955a-c6dc4f14623a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "EPOCHS = 10\n",
        "train_images_3ch_scaled = train_images_3ch / 255.\n",
        "model2.fit(train_images_3ch_scaled, train_labels, validation_split=0.1, epochs=EPOCHS)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54000/54000 [==============================] - 94s 2ms/sample - loss: 0.1911 - accuracy: 0.9448 - val_loss: 0.2108 - val_accuracy: 0.9308\n",
            "Epoch 9/10\n",
            "54000/54000 [==============================] - 94s 2ms/sample - loss: 0.1822 - accuracy: 0.9496 - val_loss: 0.2639 - val_accuracy: 0.9228\n",
            "Epoch 10/10\n",
            "54000/54000 [==============================] - 92s 2ms/sample - loss: 0.1766 - accuracy: 0.9516 - val_loss: 0.2407 - val_accuracy: 0.9317\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f706aeb2f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/10\n",
            "54000/54000 [==============================] - 98s 2ms/sample - loss: 0.5330 - accuracy: 0.8326 - val_loss: 0.3190 - val_accuracy: 0.8903\n",
            "Epoch 2/10\n",
            "54000/54000 [==============================] - 92s 2ms/sample - loss: 0.3126 - accuracy: 0.9030 - val_loss: 0.2259 - val_accuracy: 0.9150\n",
            "Epoch 3/10\n",
            "54000/54000 [==============================] - 93s 2ms/sample - loss: 0.2669 - accuracy: 0.9174 - val_loss: 0.2647 - val_accuracy: 0.9098\n",
            "Epoch 4/10\n",
            "54000/54000 [==============================] - 93s 2ms/sample - loss: 0.2513 - accuracy: 0.9245 - val_loss: 0.8622 - val_accuracy: 0.9153\n",
            "Epoch 5/10\n",
            "54000/54000 [==============================] - 94s 2ms/sample - loss: 0.2250 - accuracy: 0.9321 - val_loss: 0.2986 - val_accuracy: 0.9288\n",
            "Epoch 6/10\n",
            "54000/54000 [==============================] - 94s 2ms/sample - loss: 0.2125 - accuracy: 0.9395 - val_loss: 0.9022 - val_accuracy: 0.9193\n",
            "Epoch 7/10\n",
            "54000/54000 [==============================] - 94s 2ms/sample - loss: 0.2003 - accuracy: 0.9436 - val_loss: 0.6475 - val_accuracy: 0.9272\n",
            "Epoch 8/10\n",
            "54000/54000 [==============================] - 94s 2ms/sample - loss: 0.1868 - accuracy: 0.9482 - val_loss: 2.5179 - val_accuracy: 0.9217\n",
            "Epoch 9/10\n",
            "54000/54000 [==============================] - 95s 2ms/sample - loss: 0.1769 - accuracy: 0.9518 - val_loss: 0.2197 - val_accuracy: 0.9295\n",
            "Epoch 10/10\n",
            "54000/54000 [==============================] - 95s 2ms/sample - loss: 0.1813 - accuracy: 0.9542 - val_loss: 2.4213 - val_accuracy: 0.9043\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6cb9b22f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tncE7hA8yitg",
        "colab_type": "text"
      },
      "source": [
        "### **Save Model Weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luzUEHd-x6-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isdir('model_weights/'):\n",
        "    os.mkdir('model_weights/')\n",
        "    \n",
        "model2.save_weights(filepath='model_weights/cnn_model2_wt.h5', overwrite=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GloFApTHyrbF",
        "colab_type": "text"
      },
      "source": [
        "### **Build Model Architecture and Load Model Weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TrVUZScymrb",
        "colab_type": "code",
        "outputId": "e72017d5-68ba-41ba-ec94-ed3182ef502f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "model2 = create_cnn_architecture_model2(input_shape=INPUT_SHAPE_RN)\n",
        "model2.load_weights('model_weights/cnn_model2_wt.h5')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9dtpM7AdWfo",
        "colab_type": "text"
      },
      "source": [
        "### **Evaluate Model Performance on Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBHK2Cx8Y0Up",
        "colab_type": "code",
        "outputId": "766901b0-78b1-40c4-b2a5-505621734ef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "test_images_3ch_scaled = test_images_3ch / 255.\n",
        "predictions = model2.predict(test_images_3ch_scaled)\n",
        "predictions[:5]"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "        0.0000000e+00, 1.0000000e+00],\n",
              "       [7.8687008e-11, 3.3985192e-21, 1.0000000e+00, 7.2764182e-14,\n",
              "        2.5757187e-08, 3.0713535e-18, 1.5384455e-08, 1.4293117e-15,\n",
              "        1.2702022e-18, 5.5458073e-17],\n",
              "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "        0.0000000e+00, 0.0000000e+00],\n",
              "       [3.5385592e-26, 1.0000000e+00, 9.4518479e-26, 7.2889256e-20,\n",
              "        3.7026412e-25, 5.0788608e-24, 3.7440191e-23, 1.1049606e-26,\n",
              "        3.1358357e-28, 4.7111525e-26],\n",
              "       [1.5910782e-02, 5.0578819e-07, 1.9732801e-02, 8.9156022e-04,\n",
              "        6.8991743e-03, 1.0542024e-06, 9.5654339e-01, 4.8753864e-06,\n",
              "        1.0937049e-05, 4.8968918e-06]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.9326377e-13, 8.6979439e-21, 3.1472894e-15, 2.5944047e-16,\n",
              "        4.0900993e-15, 2.3679689e-10, 9.4139523e-12, 6.8893757e-09,\n",
              "        3.2460310e-15, 1.0000000e+00],\n",
              "       [4.2245586e-07, 1.6587563e-14, 9.9988973e-01, 2.3692506e-08,\n",
              "        1.7318271e-05, 2.0079704e-12, 9.2499802e-05, 3.3788243e-11,\n",
              "        2.3289877e-13, 3.5486091e-12],\n",
              "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
              "        0.0000000e+00, 0.0000000e+00],\n",
              "       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.5533209e-38,\n",
              "        0.0000000e+00, 4.8725277e-33, 0.0000000e+00, 0.0000000e+00,\n",
              "        0.0000000e+00, 0.0000000e+00],\n",
              "       [1.0236222e-12, 3.5296588e-35, 2.2434757e-13, 1.1600507e-16,\n",
              "        8.1422535e-11, 1.3847573e-27, 1.0000000e+00, 4.6568545e-25,\n",
              "        3.6471047e-23, 3.5894327e-26]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THA_dUd_doSV",
        "colab_type": "code",
        "outputId": "4b51a1b0-703d-4e04-ac83-b8e3351b16f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "prediction_labels = np.argmax(predictions, axis=1)\n",
        "prediction_labels[:5]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 1, 1, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 1, 1, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYNTs3Wjdz1A",
        "colab_type": "code",
        "outputId": "3438f0ba-ff2c-45ad-e382-cf259944cf0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(classification_report(test_labels, prediction_labels, target_names=class_names))\n",
        "pd.DataFrame(confusion_matrix(test_labels, prediction_labels), index=class_names, columns=class_names)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            " T-shirt/top       0.87      0.89      0.88      1000\n",
            "     Trouser       1.00      0.98      0.99      1000\n",
            "    Pullover       0.87      0.91      0.89      1000\n",
            "       Dress       0.90      0.94      0.92      1000\n",
            "        Coat       0.84      0.92      0.88      1000\n",
            "      Sandal       0.99      0.98      0.98      1000\n",
            "       Shirt       0.83      0.69      0.75      1000\n",
            "     Sneaker       0.96      0.98      0.97      1000\n",
            "         Bag       0.99      0.98      0.99      1000\n",
            "  Ankle boot       0.97      0.97      0.97      1000\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T-shirt/top</th>\n",
              "      <th>Trouser</th>\n",
              "      <th>Pullover</th>\n",
              "      <th>Dress</th>\n",
              "      <th>Coat</th>\n",
              "      <th>Sandal</th>\n",
              "      <th>Shirt</th>\n",
              "      <th>Sneaker</th>\n",
              "      <th>Bag</th>\n",
              "      <th>Ankle boot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>T-shirt/top</th>\n",
              "      <td>887</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Trouser</th>\n",
              "      <td>0</td>\n",
              "      <td>978</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pullover</th>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>906</td>\n",
              "      <td>12</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dress</th>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>937</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Coat</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>29</td>\n",
              "      <td>917</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sandal</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>978</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Shirt</th>\n",
              "      <td>112</td>\n",
              "      <td>0</td>\n",
              "      <td>65</td>\n",
              "      <td>29</td>\n",
              "      <td>103</td>\n",
              "      <td>0</td>\n",
              "      <td>689</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sneaker</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>977</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bag</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>985</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ankle boot</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             T-shirt/top  Trouser  Pullover  ...  Sneaker  Bag  Ankle boot\n",
              "T-shirt/top          887        0        20  ...        1    6           0\n",
              "Trouser                0      978         0  ...        0    1           0\n",
              "Pullover              10        0       906  ...        0    0           0\n",
              "Dress                  8        2         8  ...        0    0           0\n",
              "Coat                   1        0        36  ...        0    0           0\n",
              "Sandal                 0        0         0  ...       12    1           9\n",
              "Shirt                112        0        65  ...        0    2           0\n",
              "Sneaker                0        0         0  ...      977    0          18\n",
              "Bag                    2        1         1  ...        1  985           1\n",
              "Ankle boot             0        0         0  ...       27    1         969\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            " T-shirt/top       0.89      0.86      0.87      1000\n",
            "     Trouser       0.91      0.99      0.95      1000\n",
            "    Pullover       0.94      0.80      0.86      1000\n",
            "       Dress       0.91      0.93      0.92      1000\n",
            "        Coat       0.81      0.93      0.86      1000\n",
            "      Sandal       0.86      0.99      0.92      1000\n",
            "       Shirt       0.75      0.77      0.76      1000\n",
            "     Sneaker       0.96      0.89      0.93      1000\n",
            "         Bag       0.99      0.87      0.92      1000\n",
            "  Ankle boot       0.98      0.94      0.96      1000\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.90      0.90     10000\n",
            "weighted avg       0.90      0.90      0.90     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T-shirt/top</th>\n",
              "      <th>Trouser</th>\n",
              "      <th>Pullover</th>\n",
              "      <th>Dress</th>\n",
              "      <th>Coat</th>\n",
              "      <th>Sandal</th>\n",
              "      <th>Shirt</th>\n",
              "      <th>Sneaker</th>\n",
              "      <th>Bag</th>\n",
              "      <th>Ankle boot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>T-shirt/top</th>\n",
              "      <td>856</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>31</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>93</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Trouser</th>\n",
              "      <td>0</td>\n",
              "      <td>989</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pullover</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>798</td>\n",
              "      <td>5</td>\n",
              "      <td>92</td>\n",
              "      <td>0</td>\n",
              "      <td>95</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dress</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>927</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Coat</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>19</td>\n",
              "      <td>933</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sandal</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>993</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Shirt</th>\n",
              "      <td>87</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>30</td>\n",
              "      <td>94</td>\n",
              "      <td>0</td>\n",
              "      <td>765</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sneaker</th>\n",
              "      <td>0</td>\n",
              "      <td>84</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>892</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bag</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>114</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>869</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ankle boot</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>940</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             T-shirt/top  Trouser  Pullover  ...  Sneaker  Bag  Ankle boot\n",
              "T-shirt/top          856        0        14  ...        0    2           0\n",
              "Trouser                0      989         0  ...        0    2           0\n",
              "Pullover               9        1       798  ...        0    0           0\n",
              "Dress                  5        2         7  ...        0    1           0\n",
              "Coat                   0        0        12  ...        0    1           0\n",
              "Sandal                 0        1         0  ...        5    0           1\n",
              "Shirt                 87        1        19  ...        0    4           0\n",
              "Sneaker                0       84         0  ...      892    0          13\n",
              "Bag                    1        7         1  ...        1  869           1\n",
              "Ankle boot             0        0         0  ...       28    0         940\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aolLymM2wLyx",
        "colab_type": "text"
      },
      "source": [
        "## **Tensorflow Serving**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvRZWhQEwUor",
        "colab_type": "text"
      },
      "source": [
        "### **Saving models for Tensorflow Serving**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl8at0vR1JD2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85692357-8b8d-40be-d599-f7512829e05f"
      },
      "source": [
        "model1 = create_cnn_architecture_model1(input_shape=INPUT_SHAPE)\n",
        "model1.load_weights('./model_weights/cnn_model1_wt.h5')\n",
        "export_path = './tf_saved_models/1'\n",
        "\n",
        "# Fetch the Keras session and save the model\n",
        "# The signature definition is defined by the input and output tensors\n",
        "# And stored with the default serving key\n",
        "tf.saved_model.save(model1,export_path)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./tf_saved_models/1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CW1_4l25BVW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "26479312-15b4-4a6b-a7b0-1615f981a0bc"
      },
      "source": [
        "model2 = create_cnn_architecture_model2(input_shape=INPUT_SHAPE_RN)\n",
        "model2.load_weights('./model_weights/cnn_model2_wt.h5')\n",
        "export_path = './tf_saved_models/2'\n",
        "\n",
        "tf.saved_model.save(model2, export_path)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./tf_saved_models/2/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhlqwssS5VTB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e841c4e0-9d52-4fe6-8054-fcc8909aaa5d"
      },
      "source": [
        "! tree --du -h ."
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: tree: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za5E8V-N5Yif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}